{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General statistics on the dataset\n",
    "\n",
    "Shows table 1 in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset, concatenate_datasets, disable_caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "disable_caching()\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common import dist_funcs, new_assignments_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_df = concatenate_datasets(list(load_dataset(\"koutch/intro_prog\", \"dublin_data\").values())).to_pandas()\n",
    "start_df = start_df.replace(new_assignments_id)\n",
    "start_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concatenate_datasets(list(load_dataset(\"koutch/intro_prog\", \"dublin_repair\", \n",
    "                                            download_mode=\"force_redownload\",\n",
    "                                            ignore_verifications=True).values())).to_pandas()\n",
    "df = df.replace(new_assignments_id)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by = df.groupby(\"assignment_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of annotations per assignment\n",
    "n_submissions = grouped_by.count()[\"submission_id\"]\n",
    "n_submissions.name = \"#SS\"\n",
    "# number of students \n",
    "n_students = grouped_by.apply(lambda g: len(g.user.unique()))\n",
    "n_students.name = \"#STU\"\n",
    "n_students\n",
    "# number of non-empty annotations\n",
    "n_non_empty_annot = grouped_by.apply(lambda g: g.annotation.astype(bool).sum())\n",
    "n_non_empty_annot.name = \"#AN\"\n",
    "\n",
    "def count_avg_lines(code):\n",
    "    return len(code.splitlines())\n",
    "\n",
    "# average number of lines per submission\n",
    "avg_lines = grouped_by.apply(lambda g: g[g.annotation.astype(bool)].annotation.apply(count_avg_lines).mean())\n",
    "avg_lines = avg_lines.round(2)\n",
    "avg_lines.name = \"#lines\"\n",
    "avg_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_corr_submissions = start_df.groupby(\"assignment_id\").apply(lambda gdf: gdf[gdf.correct].count())[\"submission_id\"][n_students.index]\n",
    "ori_corr_submissions.name = \"#CC\"\n",
    "ori_corr_submissions, ori_corr_submissions.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_buggy_submissions = start_df.groupby(\"assignment_id\").apply(lambda gdf: gdf[~gdf.correct].count())[\"submission_id\"][n_students.index]\n",
    "ori_buggy_submissions.name = \"#BC\"\n",
    "ori_buggy_submissions, ori_buggy_submissions.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = start_df.groupby(\"assignment_id\").description.apply(lambda gdf: gdf.iloc[0])\n",
    "descriptions = descriptions[n_students.index]\n",
    "descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = pd.concat([descriptions, ori_corr_submissions, ori_buggy_submissions,\n",
    "                        n_non_empty_annot, avg_lines, n_students], axis=1)\n",
    "statistics.index.name = \"\"\n",
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.loc[\"total/average\"] = statistics.sum(axis=0)\n",
    "statistics.loc[\"total/average\", \"description\"] = \"\" # removing the description for the last one \n",
    "statistics.loc[\"total/average\", \"#lines\"] = statistics[\"#lines\"].mean()\n",
    "statistics[\"#lines\"] = statistics[\"#lines\"].round(2)\n",
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(statistics.to_latex(multicolumn=True, multirow=True, column_format='rlccccc'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (feedback)",
   "language": "python",
   "name": "feedback"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
